'''
Created on 14 Apr 2010

@author: tcezard
'''
from test_annotation import read_exon_capture_file,\
    get_length_of_list_range
from utils.Binning import Distribution_holder, load_distribution

from utils import utils_logging, utils_param, get_sam_stream,\
    get_mpileup_from_bam
from overlap.Binnary_search_overlap import Binnary_search,\
    Binnary_search_overlap
import logging
import sys
from optparse import OptionParser
import utils
from IO_interface.annotation_loader import Exon_annotation_Retriver
from IO_interface.samIterator import Sam_record
import os


def print_distribution(dist):
    list_values=[5,10,20,50]
    list_results=dist.get_greater_than(list_values)
    print "%s bases"%(dist.get_nb_element())
    for i in range(len(list_values)):
        print "%s bases with more than %sX coverage"%(list_results[i],list_values[i])
    print "mean coverage=%s standard deviation=%s"%(dist.get_mean(),dist.get_std_dev())
    percentiles=dist.get_percentiles([25,50,75])
    print "25 percentile=%s, 50 percentile=%s, 75 percentile=%s, "%(percentiles[0],percentiles[1],percentiles[2])

def print_distributions_table(name, dist_on_target, dist_near_target, dist_off_target, on_target_size, wiki_format=False):
    nb_bases_on_target=nb_bases_near_target=nb_bases_off_target=0
    for coverage,nb_base in dist_on_target.distribution.iteritems():
        nb_bases_on_target+=coverage*nb_base
    for coverage,nb_base in dist_near_target.distribution.iteritems():
        nb_bases_near_target+=coverage*nb_base
    for coverage,nb_base in dist_off_target.distribution.iteritems():
        nb_bases_off_target+=coverage*nb_base
    median_on_target=dist_on_target.get_median()
    mean_on_target=dist_on_target.get_mean()
    coverage_1x, coverage_10x, coverage_20x, coverage_30x, coverage_50x = dist_on_target.get_greater_or_equal_than([1,10,20,30,50])
    
    out=[]
    out.append(name)
    out.append(str(int(nb_bases_on_target)))
    if wiki_format:
        out.append('%.2f%%'%(nb_bases_on_target/(nb_bases_on_target+nb_bases_near_target+nb_bases_off_target)*100))
    out.append(str(int(nb_bases_near_target)))
    if wiki_format:
        out.append('%.2f%%'%(nb_bases_near_target/(nb_bases_on_target+nb_bases_near_target+nb_bases_off_target)*100))
    out.append(str(int(nb_bases_off_target)))
    if wiki_format:
        out.append('%.2f%%'%(nb_bases_off_target/(nb_bases_on_target+nb_bases_near_target+nb_bases_off_target)*100))
    out.append(str(int(median_on_target)))
    out.append("%.2f"%mean_on_target)
    out.append(str(coverage_1x))
    if wiki_format:
        out.append('%.2f%%'%(coverage_1x/on_target_size*100))
    out.append(str(coverage_10x))
    if wiki_format:
        out.append('%.2f%%'%(coverage_10x/on_target_size*100))
    out.append(str(coverage_20x))
    if wiki_format:
        out.append('%.2f%%'%(coverage_20x/on_target_size*100))
    out.append(str(coverage_30x))
    if wiki_format:
        out.append('%.2f%%'%(coverage_30x/on_target_size*100))
    out.append(str(coverage_50x))
    if wiki_format:
        out.append('%.2f%%'%(coverage_50x/on_target_size*100))
    if wiki_format:
        header= "|| File || # on target || % on target || # near target || % near target || # off target || % off target ||"
        header+= " Mean || Median || #bases 1X cov || %bases 1X cov || #bases 10X cov || %bases 10X cov || #bases 20X cov || %bases 20X cov ||"
        header+=" #bases 30X cov || %bases 30X cov || #bases 50X cov || %bases 50X cov ||"
        print header
        print "| %s |"%" | ".join(out)
    else:
        print "\t".join(out)

def get_ranges_and_extend_ranges(all_target_per_chr, extension=100):
    range_per_chr={}
    extended_range_per_chr={}
    for chr in all_target_per_chr.get_chr_names():
        all_ext_ranges=[]
        all_ranges=[]
        all_primary_ranges=all_target_per_chr.get_annotation_from_chr(chr)
        for range in all_primary_ranges:
            start=range[0]
            end=range[1]
            all_ranges.append((start,end))
            all_ext_ranges.append((start-extension,end+extension))
        range_per_chr[chr]=all_ranges
        extended_range_per_chr[chr]=all_ext_ranges
    return range_per_chr,extended_range_per_chr

def get_ranges_and_extend_ranges_from_center(all_target_per_chr, extension=100):
    range_per_chr={}
    extended_range_per_chr={}
    for chr in all_target_per_chr.get_chr_names():
        all_ext_ranges=[]
        all_ranges=[]
        all_primary_ranges=all_target_per_chr.get_annotation_from_chr(chr)
        for range in all_primary_ranges:
            start=range[0]
            end=range[1]
            all_ranges.append((start,end))
            all_ext_ranges.append((start-extension,end+extension))
            #center will be rounded to the floor
            center=(end+start)/2
            all_ext_ranges.append((center-extension,center+extension))
        range_per_chr[chr]=all_ranges
        extended_range_per_chr[chr]=all_ext_ranges
    return range_per_chr,extended_range_per_chr
    
def test_on_off_target(bam_file, output_template, exon_capture_file=None, annotation_file=None, extension=100, uniq_reads=False, wiki_format=False):
    if output_template:
        name=output_template
    else:
        name, ext = os.path.splitext(bam_file)
        
    if uniq_reads:
        options='-d 50000 -q 1'
        on_target_file=name+'_uniq_coverage_on_target.txt'
        near_target_file=name+'_uniq_coverage_near_target.txt'
        off_target_file=name+'_uniq_coverage_off_target.txt'
    else:
        options='-d 50000'
        on_target_file=name+'_coverage_on_target.txt'
        near_target_file=name+'_coverage_near_target.txt'
        off_target_file=name+'_coverage_off_target.txt'
    
    
    on_target_size=0
    near_target_size=0
    if exon_capture_file:
        all_target_per_chr=read_exon_capture_file(exon_capture_file, extension=0)
        all_target_ext_per_chr=read_exon_capture_file(exon_capture_file, extension=extension)
    if annotation_file:
        annotation_retriver=Exon_annotation_Retriver(annotation_file=annotation_file)
        #all_target_per_chr,all_target_ext_per_chr=get_ranges_and_extend_ranges(annotation_retriver, extension=extension)
        
        all_target_per_chr,all_target_ext_per_chr=get_ranges_and_extend_ranges_from_center(annotation_retriver, extension=extension)

    for chr in all_target_per_chr.keys():
        target_list=all_target_per_chr.get(chr)
        near_target_list=all_target_ext_per_chr.get(chr)
        on_target_size+=get_length_of_list_range(target_list)
        near_target_size+=get_length_of_list_range(near_target_list)
    
    
    
    if not os.path.exists(on_target_file) or not os.path.exists(near_target_file) or not os.path.exists(off_target_file):
        
        open_pileup = get_mpileup_from_bam(bam_file=bam_file, options=options)
        curr_chr=''
        distribution_on_target=Distribution_holder()
        distribution_near_target=Distribution_holder()
        distribution_off_target=Distribution_holder()
        nb_line=0
        all_target_search=None
        all_target_ext_search=None
        for pileup_line in open_pileup:
            sp_line=pileup_line.strip().split()
            chr=sp_line[0]
            position=int(sp_line[1])
            coverage=int(sp_line[3])
            nb_line+=1
            #if nb_line%1000000==0:
            #    print '%s lines -- position=%s:%s -- coverage=%s'%(nb_line,chr,position,coverage)
            if chr!=curr_chr:
                #print 'start %s'%chr
                all_target=all_target_per_chr.get(chr)
                all_target_ext=all_target_ext_per_chr.get(chr)
                if all_target:
                    all_target_search=Binnary_search(all_target, close_query=True)
                else:
                    all_target_search=None
                if all_target_ext:
                    all_target_ext_search=Binnary_search(all_target_ext, close_query=True)
                else:
                    all_target_search=None
                curr_chr=chr
            if all_target_search:
                results=all_target_search.ovarlap_search(position)
            else:
                results=[]
            if len(results)>0:
                distribution_on_target.add_value(coverage)
            else:
                if all_target_ext_search:
                    results=all_target_ext_search.ovarlap_search(position)
                else:
                    results=[]
                if len(results)>0:
                    distribution_near_target.add_value(coverage)
                else:
                    distribution_off_target.add_value(coverage)
        distribution_on_target.print_dist(output_file=on_target_file)
        distribution_near_target.print_dist(output_file=near_target_file)
        distribution_off_target.print_dist(output_file=off_target_file)

    else:
        distribution_on_target=load_distribution(open(on_target_file), string=False)
        distribution_near_target=load_distribution(open(near_target_file), string=False)
        distribution_off_target=load_distribution(open(off_target_file), string=False)
        
    print_distributions_table(name, distribution_on_target, distribution_near_target, distribution_off_target, on_target_size, wiki_format)
    
def test_read_on_off_target(sam_file, exon_capture_file=None, annotation_file=None, extension=100):
    """Test if reads are at least 50% of their length on target.
    It reports 3 numbers of reads: on, near and off target."""
    on_target_size=0
    near_target_size=0
    if exon_capture_file:
        all_target_per_chr=read_exon_capture_file(exon_capture_file, extension=0)
        all_target_ext_per_chr=read_exon_capture_file(exon_capture_file, extension=extension)
    if annotation_file:
        annotation_retriver=Exon_annotation_Retriver(annotation_file=annotation_file)
        all_target_per_chr,all_target_ext_per_chr=get_ranges_and_extend_ranges(annotation_retriver, extension=extension)
    
    for chr in all_target_per_chr.keys():
        target_list=all_target_per_chr.get(chr)
        near_target_list=all_target_ext_per_chr.get(chr)
        on_target_size+=get_length_of_list_range(target_list)
        near_target_size+=get_length_of_list_range(near_target_list)
    print on_target_size, near_target_size-on_target_size
    if sam_file.endswith('.bam'):
        open_sam = get_sam_stream(bam_file=sam_file,options=' -F 1028 ')
    else:
        open_sam=utils_logging.open_input_file(sam_file)
    curr_chr=''
    number_on_target=0
    number_near_target=0
    number_off_target=0
    nb_line=0
    all_target_search=None
    for sam_line in open_sam:
        samrecord = Sam_record(sam_line)
        if samrecord.is_unmapped():
            continue
        chr = samrecord.get_reference_name()
        position = samrecord.get_position()
        end = position + samrecord.get_read_length()
        nb_line+=1
        if nb_line%1000000==0:
            print '%s lines -- position=%s:%s'%(nb_line,chr,position)
        if chr!=curr_chr:
            print 'start %s'%chr
            all_target=all_target_per_chr.get(chr)
            all_target_ext=all_target_ext_per_chr.get(chr)
            if all_target:
                all_target_search=Binnary_search_overlap(all_target, close_query=True)
            if all_target_ext:
                all_target_ext_search=Binnary_search_overlap(all_target_ext, close_query=True)
            curr_chr=chr
        if all_target_search:
            results=all_target_search.ovarlap_search(position, end)
        else:
            results=[]
        
        overlap_length=0
        if len(results)>0:
            all_overlaps=[]
            for result in results:
                target, list_overlap=result
                for overlap in list_overlap:
                    all_overlaps.append(overlap)
            overlap_length = get_length_of_list_range(all_overlaps)
        if overlap_length>=samrecord.get_read_length()/2:
            number_on_target+=1
        else:
            if all_target_search:
                results=all_target_ext_search.ovarlap_search(position,end)
            else:
                results=[]
            if len(results)>0:
                all_overlaps=[]
                for result in results:
                    target, list_overlap=result
                    for overlap in list_overlap:
                        all_overlaps.append(overlap)
                overlap_length = get_length_of_list_range(all_overlaps)
            if overlap_length>=samrecord.get_read_length()/2:
                number_near_target+=1
            else:
                number_off_target+=1
    total=float(number_on_target+number_near_target+number_off_target)
    print "On target: size = %s"%on_target_size
    print "number of read on target %s (%.2f)"%(number_on_target,number_on_target/total)
    print "Near target: size=%s"%(near_target_size-on_target_size)
    print "number of read near target %s (%.2f)"%(number_near_target,number_near_target/total)
    print "Off target"
    print "number of read off target %s (%.2f)"%(number_off_target,number_off_target/total)
    

def main():
    #initialize the logging
    utils_logging.init_logging()
    #Setup options
    optparser=_prepare_optparser()
    (options,args) = optparser.parse_args()
    #verify options
    arg_pass=_verifyOption(options)
    if not arg_pass:
        logging.warning(optparser.get_usage())
        logging.critical("Non valid arguments: exit")
        sys.exit(1)
    
    
    test_on_off_target(options.bam_file, options.output_template,
                       exon_capture_file=options.exon_capture_bed_file,
                       annotation_file=options.annotation_file,
                       extension=options.extension,  uniq_reads=options.uniq_reads, 
                       wiki_format= options.wiki_format)

def _prepare_optparser():
    """Prepare optparser object. New options will be added in this
    function first.
    """
    usage = """usage: %prog <-i input> <-o outputPath> [-q quality -f]"""
    description = """This script calculate the coverage on, near and off target of the provided pileup file.
The on target region is define by a bed file and specified with -e. Alternatively a file containing annotation can be
provided as target region (UCSC, bed, gff format accepted), in this case only exons are used as a target."""
    #The input file can a pileup file or a bam file.
    prog_version=utils.getWtss_version()
    optparser = OptionParser(version="%prog of wtss_pipeline v"+prog_version,description=description,usage=usage,add_help_option=False)
    optparser.add_option("-h","--help",action="help",help="show this help message and exit.")
    optparser.add_option("-i","--bam_file",dest="bam_file",type="string",
                         help="Path to a file bam file with the aligned reads. Default: %default")
    optparser.add_option("-o","--output",dest="output_template",type="string",
                         help="Path to a file template name used to create the output files. Default: %default")
    optparser.add_option("-e","--exon_capture_bed_file",dest="exon_capture_bed_file",type="string",
                         help="The file containing the probe position. Default: %default")
    optparser.add_option("-a","--annotation_file",dest="annotation_file",type="string",
                         help="replace the probe by any annotation. Default: %default")
    optparser.add_option("-x","--extension",dest="extension",type="int",default=100,
                         help="Extension of the target region to define the near target region. Default: %default")
    optparser.add_option("-u","--uniq_reads",dest="uniq_reads",action="store_true",default=False,
                         help="Use only the unique reads to calculate coverage. Default: %default")
    optparser.add_option("-w","--wiki_format",dest="wiki_format",action="store_true",default=False,
                         help="Output the table in wiki format. Default: %default")
    
   
    
    return optparser

def _verifyOption(options):
    """Check if the mandatory option are present in the options objects.
    @return False if any argument is wrong."""
    arg_pass=True
    
    # Test output_file
    arg_pass and utils_param.check_input_file(options.bam_file, pipe_allowed=False)
    if not options.exon_capture_bed_file and not options.annotation_file:
        logging.error("You must specify an exon capture bed file or an annotation file.")
        arg_pass=False
    
    return arg_pass


if __name__=="__main__":
    main()

if __name__=="1__main__":
    bam_file = '/home/tcezard/projects/2010142_Sahota_Surinder/2010_SOL_SS341__SS1/bwa_merged/2010_SOL_SS341_1_run_elemt_realigned_mark_dups.bam'
    output_file= '/home/tcezard/temp/test_read_on_off_target_'
    exon_capture_file= '/home/tcezard/old_projects/exons_capture_evaluation/agilent/source/SureSelect_All_Exon_50mb_with_annotation.hg19.bed.gz'
    
    test_read_on_off_target(bam_file, output_file, exon_capture_file)
    
