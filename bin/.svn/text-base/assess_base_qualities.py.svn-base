'''
Created on 26 Aug 2010

@author: tcezard
'''
#/usr/bin/env python

import sys,os,logging
from optparse import OptionParser
from IO_interface.samIterator import Sam_record
import utils
from utils import pipeline_constant as constant, utils_logging, benchmarck_timer
from utils.Binning import Distribution_holder
import HTSeq

TYPE_SAM="sam"
TYPE_FASTQ="fastq"
ACCEPTED_TYPES=[TYPE_SAM, TYPE_FASTQ]
QUALITY_SOLEXA_OLD='solexa_old'
QUALITY_SOLEXA='solexa'
QUALITY_SANGER='phred'
QUALITY_ACCEPTED=[QUALITY_SOLEXA_OLD,QUALITY_SOLEXA,QUALITY_SANGER]

def _prepare_optparser():
    """Prepare optparser object.
    """
    usage = """usage: %prog -h
       %prog -i <input_file> -o <directory> [-t type] [-n name] [-a]"""
    desc_list = []
    desc_list.append('This script take reads in fastq or sam format and calculate')
    desc_list.append('the base quality distribution.')
    description = ' '.join(desc_list)
    
    prog_version='UNVERSIONED' #utils.getWtss_version()
    optparser = OptionParser(version="%prog of wtss_pipeline v"+prog_version,description=description,usage=usage,add_help_option=False)
    optparser.add_option("-h","--help",action="help",help="show this help message and exit.")
    optparser.add_option("-i","--input",dest="input_file",type="string",
                         help="""Full path to the input file.
You can use the keyword PIPE and the input will be read from the standard input. Default: %default""")    
    optparser.add_option("-o","--outDir",dest="outputDir",type="string",
                         help="""The directory where the stats files will be stored. Default: %default""")
    optparser.add_option("-t","--type",dest="type",type="string",default="fastq",
                         help="The type of input file used ("+", ".join(ACCEPTED_TYPES)+") Default: %default")
    optparser.add_option("-q","--quality_scale",dest="quality_scale",type="string",default=QUALITY_SOLEXA,
                         help="The type of quality encoding used ("+", ".join(ACCEPTED_TYPES)+") Default: %default")
    optparser.add_option("-n","--name",dest="name",type="string",
                         help="The name of the output file. Default: %default")
    
    return optparser


def _verifyOption(options):
    """Check if the mandatory option are present in the options objects."""
    arg_pass=True
    if not options.outputDir :
        logging.error("You must specify a output directory")
    if not options.input_file:
        logging.error('You must specify an input file with -i <file or PIPE>.')
        arg_pass=False
    elif options.input_file!="PIPE" and not os.path.exists(options.input_file):
        logging.error('Specified input file "%s" does not exist.' % (options.input_file))
        arg_pass=False
    if not options.type.lower() in ACCEPTED_TYPES:
        logging.error("Unrecognize format %s. Use one of %s"%(options.type.lower(), ", ".join(ACCEPTED_TYPES)))
        arg_pass=False
    return arg_pass

def assessQV_from_fastq(fastq_file, quality_scale):
    open_input=utils_logging.open_input_file(fastq_file)
    quality_generator = read_fastq(open_input, quality_scale)
    return assessQV(quality_generator)

def assessQV(quality_generator):
    totalcount = 0
    read_len_quality=Distribution_holder()
    
    distrib_for_each_base=None
    benchmarck_timer.start('loop and reading')
    for qual_array in quality_generator:
        benchmarck_timer.stop('loop and reading')
        
        benchmarck_timer.start('test distrib_for_each_base is None')
        if distrib_for_each_base is None:
            distrib_for_each_base=[Distribution_holder() for dummy in range(len(qual_array)) ]
        benchmarck_timer.stop('test distrib_for_each_base is None')
        
        totalcount+=1
        nb_high_qual_base=0
        benchmarck_timer.start('Process fully one read')
        for pos in range(len(qual_array)):
            benchmarck_timer.start('add to distrib_for_each_base')
            distrib_for_each_base[pos].add_value(qual_array[pos])
            benchmarck_timer.stop('add to distrib_for_each_base')
            benchmarck_timer.start('test good quality of the read')
            if qual_array[pos] > 20 :
                nb_high_qual_base+=1
            benchmarck_timer.stop('test good quality of the read')
        #store all len of above 20 quality
        benchmarck_timer.start('add to read_len_quality')
        read_len_quality.add_value(float(nb_high_qual_base)/len(qual_array))
        benchmarck_timer.stop('add to read_len_quality')
        benchmarck_timer.stop('Process fully one read')
        
        benchmarck_timer.start('loop and reading')
    benchmarck_timer.stop('loop and reading')
    benchmarck_timer.print_all()
    print '%s reads'%totalcount
    return (totalcount, read_len_quality, distrib_for_each_base)

def assessQV_with_color_space(open_input, qual_position, qualityOffset, flag):
    totalcount_true = 0
    totalcount_false = 0
    line=open_input.readline()
    flag_true, qual_str, col_qual_string=read_solid_sam(line, flag)
    distrib_for_each_base_true=[Distribution_holder() for dummy in range(len(qual_str))]
    distrib_for_each_color_true=[Distribution_holder() for dummy in range(len(col_qual_string))]
    distrib_for_each_base_false=[Distribution_holder() for dummy in range(len(qual_str))]
    distrib_for_each_color_false=[Distribution_holder() for dummy in range(len(col_qual_string))]
    while line:
        flag_true, qual_string, col_qual_string=read_solid_sam(line,flag)
        if flag_true:
            totalcount_true+=1
            distrib_for_each_base=distrib_for_each_base_true
            distrib_for_each_color=distrib_for_each_color_true
        else:
            totalcount_false+=1
            distrib_for_each_base=distrib_for_each_base_false
            distrib_for_each_color=distrib_for_each_color_false
        for pos in range(len(qual_string)):
            value=ord(qual_string[pos])-qualityOffset
            distrib_for_each_base[pos].add_value(value)
        for pos in range(len(col_qual_string)):
            value=ord(col_qual_string[pos])-qualityOffset
            distrib_for_each_color[pos].add_value(value)
        line=open_input.readline()
        if (totalcount_true+totalcount_false)%1000000==0:
            print totalcount_true, totalcount_false
    
    return (totalcount_true, totalcount_false, distrib_for_each_base_true, distrib_for_each_color_true,
            distrib_for_each_base_false, distrib_for_each_color_false)


def read_solid_sam(line, flag):
    #1542_740_1722   153     1       470     255     31M     *       0       0       GCGGTACCCTCAGCCGGCCCGCCCGCCCGGG III&&III..II++IIC?9?IIF1:III6=I RG:Z:R3 CS:Z:G30030033003300303002120001300330020010000000000000        CO:i:0  CQ:Z:5;#4<<5&,;<:&4,888+37=.4<55&8;1:3/=:7=85;:6;<:<;6=
    sam_record=Sam_record(line)
    qual_str=sam_record.get_query_quality()
    col_qual_string=sam_record.get_tag('CQ')
    if col_qual_string is None:
        logging.error("can't find color space quality string in %s!!!"% line)
        
    return (sam_record._check_bit(int(flag)),qual_str,col_qual_string)

def read_sam(open_file):
    for line in open_file:
        sam_record=Sam_record(line)
        qual_str=sam_record.get_query_quality()
        qual=[ord(char)-33 for char in qual_str]
        yield qual


def read_fastq(file, qual_scale = 'solexa'):
    fastq_reader = HTSeq.FastqReader(file_ = file, qual_scale = qual_scale)
    for fastq_record in fastq_reader:
        yield fastq_record.qual

def output_to_files(output_dir, name, distrib_for_each_base, totalcount):
    outfilename=os.path.join(output_dir,name+'_base_distrib.qv')
    all_qual=set()
    open_file=open(outfilename, 'w')
    for pos in range(len(distrib_for_each_base)):
        set_of_qual=distrib_for_each_base[pos].get_values()
        all_qual.update(set(set_of_qual))
    out=[]
    for qual in all_qual:
        out.append(str(qual))
        for pos in range(len(distrib_for_each_base)):
            if distrib_for_each_base[pos].get_nb_of_value(qual):
                out.append(str(distrib_for_each_base[pos].get_nb_of_value(qual)))
            else:
                out.append('0')
        open_file.write('%s\n'%('\t'.join(out)))
    open_file.close()
    logging.info('Complete distribution of QVs is in %s' % outfilename)
    outfilename=os.path.join(output_dir,name+'_mean_median.qv')
    open_mean=open(outfilename, 'w')
    #calculate the mean and median for each base
    for pos in range(len(distrib_for_each_base)):
        mean=distrib_for_each_base[pos].get_mean()
        std_dev=distrib_for_each_base[pos].get_std_dev()
        all_percentiles=distrib_for_each_base[pos].get_percentiles([25,50,75])
        open_mean.write('%s\t%s\t%s\t%s\n' % (pos+1,mean,std_dev,'\t'.join([str(x) for x in all_percentiles])))
    open_mean.close()
    logging.info('Mean and median QVs are in %s' % outfilename)
    outfilename=os.path.join(output_dir,name+'_distrib.qv')
    open_distrib=open(outfilename, 'w')
    #sum the base of each distrib
    for qual in all_qual:
        sum=0
        for pos in range(len(distrib_for_each_base)):
            if distrib_for_each_base[pos].get_nb_of_value(qual):
                sum+=distrib_for_each_base[pos].get_nb_of_value(qual)
        open_distrib.write('%s\t%s\n'%(qual,sum))
    open_distrib.close()
    logging.info('Global distribution of QVs is in %s' % outfilename)


def main():
    console = logging.StreamHandler(sys.stdout)
    console.setLevel(logging.INFO)
    console.setFormatter(logging.Formatter(constant.default_log_Format))
    logging.getLogger('').addHandler(console)
    logging.getLogger('').setLevel(logging.NOTSET)
    optparser=_prepare_optparser()
    (options,dummy) = optparser.parse_args()
    
    arg_pass =_verifyOption(options)
    if not arg_pass:
        logging.warning(optparser.get_usage())
        logging.critical("Non valid arguments: exit")
        sys.exit(1)
    
    #Create the output dir if not exists
    utils.createDirectories('', [options.outputDir])
    #call the main body function passing params
    open_input=utils_logging.open_input_file(options.input_file)
    if options.name:
        name=options.name
    else:
        (name, dummy)=os.path.splitext(os.path.basename(options.input_file))
    
    if options.type.lower()==TYPE_SAM:
        quality_generator = read_sam(open_input)
    elif options.type.lower() == TYPE_FASTQ:
        quality_generator = read_fastq(open_input, options.quality_scale)
    (totalcount, read_len_quality, distrib_for_each_base) = assessQV(quality_generator)
    
    output_to_files(options.outputDir, name, distrib_for_each_base, totalcount)
    

if __name__ == '__main__':
    utils_logging.init_logging()
    file= '/home/tcezard/temp/100813_621NOAAXX_2_0_2.part.fastq'
    assessQV_from_fastq(file, 'solexa')
