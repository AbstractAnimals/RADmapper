#!/usr/bin/env python
import os, sys, logging, glob
from optparse import OptionParser
from utils import utils_logging, utils_param
from utils import getWtss_version
import utils
from get_data_from_seqarchive import get_files_from_seq_archive,\
    get_link_from_seq_archive, copy_file_across
from wiki_communication import get_wiki_project
from utils.utils_commands import shellize_file_name
import command_runner

informations_file="""
Directories:

 - 1. raw_reads: contains the raw reads
 
1. raw_reads:
 - one directory per sample,  one (single-end) or two (paired) file(s) per lane
 - each run name is created out date.of.run_run.number_flowcell_lane_index_readnumber_solfastq.gz
    - date.of.run: when the run was started.
    - run.number: incremental number.
    - machine.run_counter: the run number for this sequencer.
    - flowcell: The unique flowcell id that was use in the sequencer for your run
    - lane: The lane in the flowcell where your sample was run
    - index: The index id used to barcode your sample. 0 means no index was used.
    - readnumber: 1 for read 1, 2 for read 2 (for paired-end runs)
 
The raw reads are in Solexa 1.3+ fastq format (http://en.wikipedia.org/wiki/FASTQ_format#Illumina_sequence_identifiers)
"""

aligned_informations_file="""
Directories:

 - 1. raw_reads: contains the raw reads
 - 2. aligned_reads: contains the reads aligned to the reference genome
 
1. raw_reads:
 - one directory per sample,  one (single-end) or two (paired) file(s) per lane
 - each run name is created out date.of.run_flowcell_lane_index_readnumber_solfastq.gz
    - date.of.run: when the run was done.
    - flowcell: The unique flowcell id that was use in the sequencer for your run
    - lane: The lane in the flowcell where your sample was run
    - index: The index id used to barcode your sample. 0 means no index was used.
    - readnumber: 1 for read 1, 2 for read 2 (for paired-end runs)
 
The raw reads are in Solexa 1.3+ fastq format (http://en.wikipedia.org/wiki/FASTQ_format#Illumina_sequence_identifiers)


2. aligned_reads:
  - one directory per sample
  - each directory contains 3 files:
    - A bam file containing all reads aligned or unaligned: binnary format (see http://samtools.sourceforge.net/SAM1.pdf)
    - A bai file: index of the bam file used to fast access of the reads in the bam file. binnary format
    - A .stat file: Contains some basic mapping stats from the bam file output by "samtools flagstat". Text format
"""

information_file_to_transfert=informations_file

example_process="""
Process followed:
 1. Reads are mapped with bwa (version 0.5.8) to human genome (version hg19) 
 
 2. All runs were merged per sample to create one bam file per sample using samtools (version 0.1.10)

 3. Read are realigned arround Indels with GATK (v1.0.4705) using humane genome (version hg19)

 4. Snps were called with GATK (v1.0.4705) thresholding base quality at 20 and mapping quality at 10, dbsnps annotation was taken from dbsnp131.

 5. Snps with less than 10 supporting reads were filtered using vcfutils (part of samtools 0.1.10)

 6. Snps were annotated with Refseq genes downloaded from UCSC.

"""
example_directory="""
Directories:

 - 1. raw_reads: contains the raw reads
 - 2. aligned_reads: contains the reads aligned to the reference genome (hg19)
 - 3. snps_and_indels: contains the snps and the indel called and annotated
 
1. raw_reads:
 - one directory per sample,  one (single-end) or two (paired) file(s) per lane
 - each run name is created out date.of.run_flowcell_lane_index_readnumber_solfastq.gz
    - date.of.run: when the run was done.
    - flowcell: The unique flowcell id that was use in the sequencer for your run
    - lane: The lane in the flowcell where your sample was run
    - index: The index id used to barcode your sample. 0 means no index was used.
    - readnumber: 1 for read 1, 2 for read 2 (for paired-end runs)
 
The raw reads are in Solexa 1.3+ fastq format (http://en.wikipedia.org/wiki/FASTQ_format#Illumina_sequence_identifiers)


2. aligned_reads:
  - one directory per sample
  - each directory contains 3 files:
    - A bam file containing all reads aligned or unaligned: binnary format (see http://samtools.sourceforge.net/SAM-1.3.pdf)
    - A bai file: index of the bam file used to fast access of the reads in the bam file. binnary format
    - A .stat file: Contains some basic mapping stats from the bam file output by "samtools flagstat". Text format

3. snps_and_indels:
 - one directory per sample:
 - each directory contains 4 files:
    - A vcf file ending in _snps.vcf containing snps called by GATK with no filtering. Text format (see http://www.1000genomes.org/wiki/Analysis/Variant%20Call%20Format/vcf-variant-call-format-version-40)
      The format is describe online but I'll give a quick summary:
column 1: Chomosome name
column 2: Coordinate on the chromosome
column 3: An dbsnp131 id if it exist (.) otherwise
column 4: The base found in the reference genome at that position
column 5: The snps base found in the sample
column 6: A Phred scaled quality of the snps (-10log_10 p(variant_being_wrong))
column 7: Unused field
column 8: INFO specific to GATK see online definition for detail
column 9: INFO specific to GATK see online definition for detail
column 10: INFO specific to GATK see online definition for detail
    - A vcf file ending in _snps_dp10.vcf that contains snps called by GATK with at least a depth of 10. Text format
    - An anno file based on the vcf format with more columns with following format:
column 11: gene id
column 12: strand
column 13: transcript id
column 14: type (intergenic, intron, exon, 5'UTR, 3'UTR or cds)
column 15: exon/intron number
column 16: original codon
column 17: position in the codon
column 18: new codon
column 19: original amino acid
column 20: new amino acid
column 21: coding status (SYNONYMOUS or CODING)
    - An anno.summary file based on the vcf format with more columns with following format:
column 11: type (intergenic, intron, exon, 5'UTR, 3'UTR or cds)
column 12: coding status (SYNONYMOUS or CODING)

"""


email_to_send="""
Dear %s,
Your sample has been sequenced and the raw data are now available on our webserver at
%s
This directory is protected by EASE authentication and I'll need to have your ease login to allow you access along with anybody else that'll need access.

Thank you,

Tim 
"""

htaccess_file="""CosignProtected         On
AuthType Cosign
require user tcezard
require user nmoir
require user utrivedi
require user mblaxter
require user sbridget
require user kgharbi
require user jdavey
require user gkaur
"""

def copy_files(project_id, aligned_reads=False, link=False, overwrite=False):
    pipeline_place = utils_param.get_pipeline_places()
    webserver_dir = pipeline_place.get_webserver_dir()
    server,parent_dest_dir = webserver_dir.split(':')
    
    project = get_wiki_project(project_id)
    if project:
        output_project_dir=os.path.join(parent_dest_dir,shellize_file_name(project.get_project_page_title()))
        utils.createDirectories(baseDir='', directories=[output_project_dir], server=server)
        #Transfert raw data
        if link:
            link_raw_data_to_webserver(project, server, output_project_dir, overwrite)
        else:
            copy_raw_data_to_webserver(project, server, output_project_dir, overwrite)
        
        if aligned_reads:
            copy_aligned_reads_to_webserver(project, server, output_project_dir, overwrite)
            global information_file_to_transfert
            information_file_to_transfert=aligned_informations_file
        #Transfert general files
        transfert_information_file(server, output_project_dir, overwrite)


def copy_raw_data_to_webserver(project, server, project_dir, overwrite):
    raw_reads_dir=os.path.join(project_dir, 'raw_reads')
    utils.createDirectories(baseDir='', directories=[raw_reads_dir], server=server)
    for sample in project.get_samples():
        if len(sample.get_run_elements())>0:
            sample_dir=os.path.join(raw_reads_dir,shellize_file_name(sample.get_external_id()))
            utils.createDirectories(baseDir='', directories=[sample_dir], server=server)
            for run_element in sample.get_run_elements():
                if run_element.is_usable():
                    fastq_files= get_files_from_seq_archive(run_element, sample_dir,
                                               server_destination=server,overwrite=overwrite)
                    # change the mode to make is accessible to the webserver
                    command = 'ssh %s "chmod 664 %s"'%(server, ' '.join(fastq_files))
                    command_runner.run_command(command)


def link_raw_data_to_webserver(project, server, project_dir):
    raw_reads_dir=os.path.join(project_dir, 'raw_reads')
    utils.createDirectories(baseDir='', directories=[raw_reads_dir], server=server)
    for sample in project.get_samples():
        sample_dir=os.path.join(raw_reads_dir,shellize_file_name(sample.get_external_id()))
        utils.createDirectories(baseDir='', directories=[sample_dir], server=server)
        for run_element in sample.get_run_elements():
            if run_element.is_usable():
                fastq_files= get_link_from_seq_archive(run_element, sample_dir,
                                           server_destination=server, overwrite=overwrite)


def copy_aligned_reads_to_webserver(project, server, output_project_dir, overwrite):
    output_aligned_reads_dir=os.path.join(output_project_dir, 'aligned_reads')
    utils.createDirectories(baseDir='', directories=[output_aligned_reads_dir], server=server)
    pipeline_place = utils_param.get_pipeline_places()
    input_all_project_dir=pipeline_place.get_illumina_project_dir()
    input_project_dir = glob.glob(os.path.join(input_all_project_dir,project.id+'*'))
    bwa_merged_dirname ='bwa_merged'
    if len(input_project_dir)==1 and os.path.isdir(input_project_dir[0]):
        input_project_dir = input_project_dir[0]
        for sample in project.get_samples():
            #look for bwa_merged directory
            input_bwa_merged_reads_dir=os.path.join(input_project_dir,sample.id+'__'+shellize_file_name(sample.get_external_id()),
                                                    bwa_merged_dirname)
            if os.path.isdir(input_bwa_merged_reads_dir):
                #create the sample directory on the webserver
                output_sample_aligned_reads_dir=os.path.join(output_aligned_reads_dir, shellize_file_name(sample.get_external_id()))
                utils.createDirectories(baseDir='', directories=[output_sample_aligned_reads_dir], server=server)
                #now look for a bam file.
                input_sample_bam_file = glob.glob(os.path.join(input_bwa_merged_reads_dir, '*.bam'))
                if len(input_sample_bam_file)==1:
                    input_sample_bam_file=input_sample_bam_file[0]
                    print os.path.join(input_sample_bam_file,'*.bam')
                    output_file_name = os.path.join(output_sample_aligned_reads_dir,
                                                    sample.get_external_id()+'.bam')
                    
                    copy_file_across(input_sample_bam_file, output_file_name, 
                                     server_destination = server, overwrite=overwrite)
                else:
                    logging.error("Found %s bam file: can't transfer!!"%(len(input_sample_bam_file)))
                
                input_sample_bamstat_file=glob.glob(os.path.join(input_bwa_merged_reads_dir,'*.bam.stat'))
                if len(input_sample_bamstat_file)==1:
                    input_sample_bamstat_file=input_sample_bamstat_file[0]
                    print os.path.join(input_sample_bamstat_file,'*.bam.stat')
                    output_file_name = os.path.join(output_sample_aligned_reads_dir, sample.get_external_id()+'.bam.stat')
                    
                    copy_file_across(input_sample_bamstat_file, output_file_name, 
                                     server_destination = server, overwrite=overwrite)
                else:
                    logging.warning("Found %s bam.stat file: can't transfer!!"%(len(input_sample_bamstat_file)))
                    
                input_sample_bambai_file=glob.glob(os.path.join(input_bwa_merged_reads_dir,'*.bam.bai'))
                if len(input_sample_bambai_file)==1:
                    input_sample_bambai_file=input_sample_bambai_file[0]
                    print os.path.join(input_sample_bamstat_file,'*.bam.bai')
                    output_file_name = os.path.join(output_sample_aligned_reads_dir, sample.get_external_id()+'.bam.bai')
                    
                    copy_file_across(input_sample_bambai_file, output_file_name, 
                                     server_destination = server, overwrite=overwrite)
                else:
                    logging.warning("Found %s bam.bai file: can't transfer!!"%(len(input_sample_bambai_file)))
                
                
            else:
                logging.error("%s can't be found on for this project"%input_bwa_merged_reads_dir)
        
    else:
        logging.error("Found %s project directory for project id %s"%(len(input_project_dir), project.id))

    

def transfert_information_file(server, project_dir, overwrite):
    info_file_name='Information.txt'
    htaccess_name='.htaccess'
    info_file = open(info_file_name,'w')
    info_file.write(information_file_to_transfert)
    info_file.close()
    htaccess = open(htaccess_name,'w')
    htaccess.write(htaccess_file)
    htaccess.close()
    copy_file_across(info_file_name, project_dir, server_destination = server, overwrite=overwrite)
    os.remove(info_file_name)
    copy_file_across(htaccess_name, project_dir, server_destination = server, overwrite=overwrite)
    os.remove(htaccess_name)
    command = 'ssh %s "chmod 664 %s %s"'%(server, os.path.join(project_dir,info_file_name), os.path.join(project_dir,htaccess_name))
    command_runner.run_command(command)
    

def main():
    #initialize the logging
    utils_logging.init_logging(logging.INFO)
    #Setup options
    optparser=_prepare_optparser()
    (options, args) = optparser.parse_args()
    #verify options
    arg_pass=_verifyOption(options)
    if not arg_pass:
        logging.warning(optparser.get_usage())
        logging.critical("Non valid arguments: exit")
        sys.exit(1)
    if options.debug:
        utils_logging.init_logging(logging.DEBUG)
    command_runner.set_command_to_run_localy()
    copy_files(options.project_id,aligned_reads=options.aligned_reads,
               link=options.link, overwrite=options.force)


def _prepare_optparser():
    """Prepare optparser object. New options will be added in this
    function first.
    """
    usage = """usage: %prog [-l] <-p project number> """
    description = """This script dessiminate all data to the webserver."""
    
    prog_version=getWtss_version()
    optparser = OptionParser(version="%prog of wtss_pipeline v"+prog_version,description=description,usage=usage,add_help_option=False)
    optparser.add_option("-h","--help",action="help",help="show this help message and exit.")
    optparser.add_option("-p","--project_id",dest="project_id",type="string",
                         help="project id. Default: %default")
    optparser.add_option("-a","--aligned_reads",dest="aligned_reads",action="store_true",default=False,
                         help="Transfert the aligned reads found in bwa_merged directory. Default: %default")
    optparser.add_option("-l","--link",dest="link",action="store_true",default=False,
                         help="Set the script to create links instead of copying. Default: %default")
    optparser.add_option("-f","--force",dest="force",action="store_true",default=False,
                         help="Set the script to overwrite all file if they already exist. Default: %default")
    optparser.add_option("--debug",dest="debug",action="store_true",default=False,
                         help="Set the script to output debug information. Default: %default")
    return optparser


def _verifyOption(options):
    """Check if the mandatory option are present in the options objects.
    @return False if any argument is wrong."""
    arg_pass=True
    
    if not options.project_id:
        logging.error("You must specify a project id")
        arg_pass=False
    return arg_pass



if __name__=="__main__":
    main()
